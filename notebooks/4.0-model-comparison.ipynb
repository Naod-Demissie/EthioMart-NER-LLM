{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgHJNsORk6FH"
      },
      "source": [
        "# <center><font color = '#DF9166' size = 20 center> **Model Interpretation**</font></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fSpndrWlE65"
      },
      "source": [
        "## <font color = '#DF9166' size=6>**Table of content**<font/><a class = 'anchor' id = 'introduction'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5GKG9uVDuCt"
      },
      "source": [
        "1. [**Import Libraries**](#import)\n",
        "2. [**Data Loading**](#data_loading)\n",
        "3. [**Model and Tokenizer Loading**](#model_loading)\n",
        "4. [**Model Comparison**](#model_comparison)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QN6GMz4DwgL"
      },
      "source": [
        "## <font color = '#DF9166' size=6>**Import Libraries**<font/><a class = 'anchor' id = 'import'/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gaK7-RaMD32O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "from IPython.display import Image\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sys.path.append(os.path.abspath(os.pardir))\n",
        "from scripts.train import load_conll_file\n",
        "from scripts.compare import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8SBgmebvuU-"
      },
      "source": [
        "## <font color = '#DF9166' size=6>**Data Loading**<font/><a class = 'anchor' id = 'data_loading'/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TmyZBmIVv28j"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = (\n",
        "    \"/content/drive/MyDrive/10 acadamy/W5 Challenge/data/processed/labeled_data.conll\"\n",
        ")\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0FNvKOSv1hj",
        "outputId": "75884659-116a-493d-faad-8736fd12b212"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 1850\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 232\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 231\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataset from your CoNLL file\n",
        "dataset = load_conll_file(DATA_PATH, SEED)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c3phiTOfbZxG"
      },
      "outputs": [],
      "source": [
        "# Extract texts and labels\n",
        "texts = dataset[\"test\"][\"tokens\"]\n",
        "labels = dataset[\"test\"][\"ner_tags\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXv5qactIin2"
      },
      "source": [
        "## <font color = '#DF9166' size=6>**Model and Tokenizer Loading**<font/><a class = 'anchor' id = 'model_loading'/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0QPv2MLI4n4",
        "outputId": "9b98255b-c1bc-4d27-8df7-bd4c7633a7e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "DSTLBERT_MODEL_NAME = \"Naod-Demissie/distlbert-amh-telegram-trained-merged\"\n",
        "BERT_MODEL_NAME = \"Naod-Demissie/bert-amh-telegram-trained-merged\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
        "bert_model = AutoModelForTokenClassification.from_pretrained(BERT_MODEL_NAME)\n",
        "bert_pipeline = pipeline(\n",
        "    \"ner\", model=bert_model, tokenizer=bert_tokenizer, aggregation_strategy=\"none\"\n",
        ")\n",
        "\n",
        "dstlbert_tokenizer = AutoTokenizer.from_pretrained(DSTLBERT_MODEL_NAME)\n",
        "dstlbert_model = AutoModelForTokenClassification.from_pretrained(DSTLBERT_MODEL_NAME)\n",
        "dstlbert_pipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model=dstlbert_model,\n",
        "    tokenizer=dstlbert_tokenizer,\n",
        "    aggregation_strategy=\"none\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8aIjvnFfqlL"
      },
      "source": [
        "## <font color = '#DF9166' size=6>**Model Comparison**<font/><a class = 'anchor' id = 'model_comparison'/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLU0x4BGcgPi",
        "outputId": "d078b5a1-9b38-4777-bc92-0bceeb8d468a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bert Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.05      0.09      0.06       629\n",
            "       PRICE       0.00      0.00      0.00       254\n",
            "     PRODUCT       0.01      0.36      0.02       476\n",
            "\n",
            "   micro avg       0.01      0.17      0.02      1359\n",
            "   macro avg       0.02      0.15      0.03      1359\n",
            "weighted avg       0.02      0.17      0.04      1359\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Bert Model\n",
        "y_true_bert, y_pred_bert = align_labels_and_predictions(\n",
        "    texts, labels, bert_tokenizer, bert_pipeline\n",
        ")\n",
        "\n",
        "print(\"Bert Model Classification Report:\")\n",
        "print(classification_report(sum(y_true_bert, []), sum(y_pred_bert, [])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ks98ylkc55r",
        "outputId": "31fcb4d6-ae88-41a0-d889-84197304be66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dstlbert Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.01      0.05      0.02       622\n",
            "       PRICE       0.00      0.00      0.00       254\n",
            "     PRODUCT       0.01      0.29      0.02       463\n",
            "\n",
            "   micro avg       0.01      0.13      0.02      1339\n",
            "   macro avg       0.01      0.12      0.01      1339\n",
            "weighted avg       0.01      0.13      0.02      1339\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Dislbert Model\n",
        "y_true_dstlbert, y_pred_dstlbert = align_labels_and_predictions(\n",
        "    texts, labels, dstlbert_tokenizer, dstlbert_pipeline\n",
        ")\n",
        "\n",
        "print(\"dstlbert Model Classification Report:\")\n",
        "print(classification_report(sum(y_true_dstlbert, []), sum(y_pred_dstlbert, [])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9YUWtj7d0yR"
      },
      "source": [
        "### Per-Entity Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFYJfIgIligf",
        "outputId": "f266e4cb-cf8e-4d2f-aacb-e5535e1c01f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bert Model Per-Entity Performance: {'LOC': {'Precision': 0.038430089942763694, 'Recall': 0.07556270096463022, 'F1-score': 0.05094850948509484}, 'PRICE': {'Precision': 0.0, 'Recall': 0.0, 'F1-score': 0.0}, 'PRODUCT': {'Precision': 0.008504734905603474, 'Recall': 0.3045356371490281, 'F1-score': 0.01654735359699566}, 'micro avg': {'Precision': 0.010549943883277216, 'Recall': 0.140403286034354, 'F1-score': 0.01962524140090819}, 'macro avg': {'Precision': 0.015644941616122388, 'Recall': 0.1266994460378861, 'F1-score': 0.0224986210273635}, 'weighted avg': {'Precision': 0.02079253786832967, 'Recall': 0.140403286034354, 'F1-score': 0.02938864646388199}}\n",
            "Distlbert Model Per-Entity Performance: {'LOC': {'Precision': 0.014385353095030515, 'Recall': 0.05305466237942122, 'F1-score': 0.02263374485596708}, 'PRICE': {'Precision': 0.0, 'Recall': 0.0, 'F1-score': 0.0}, 'PRODUCT': {'Precision': 0.008276533592989289, 'Recall': 0.2937365010799136, 'F1-score': 0.01609943770346256}, 'micro avg': {'Precision': 0.009021031280025621, 'Recall': 0.1262135922330097, 'F1-score': 0.016838539331440243}, 'macro avg': {'Precision': 0.007553962229339934, 'Recall': 0.11559705448644493, 'F1-score': 0.012911060853143213}, 'weighted avg': {'Precision': 0.009544230529247962, 'Recall': 0.1262135922330097, 'F1-score': 0.01608082819799454}}\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Bert Model Per-Entity Performance:\",\n",
        "    per_entity_report(sum(y_true_bert, []), sum(y_pred_bert, [])),\n",
        ")\n",
        "print(\n",
        "    \"Distlbert Model Per-Entity Performance:\",\n",
        "    per_entity_report(sum(y_true_dstlbert, []), sum(y_pred_dstlbert, [])),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXO25k9dgcSa"
      },
      "source": [
        "### Inference Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ybWK05CgG3r",
        "outputId": "cb7e3472-6293-4719-d1e4-0ffea9d9998a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bert Model Avg Inference Time: 0.8243 sec/sentence\n",
            "Distlbert Model Avg Inference Time: 0.4932 sec/sentence\n"
          ]
        }
      ],
      "source": [
        "time_bert = measure_inference_time(bert_pipeline, texts)\n",
        "time_dstlbert = measure_inference_time(dstlbert_pipeline, texts)\n",
        "\n",
        "print(f\"Bert Model Avg Inference Time: {time_bert:.4f} sec/sentence\")\n",
        "print(f\"Distlbert Model Avg Inference Time: {time_dstlbert:.4f} sec/sentence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBd_CdhIge_z"
      },
      "source": [
        "### Model Size Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKE0uGgcgXuH",
        "outputId": "38c47d3d-dea0-4f3f-857f-66d91bdfb60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bert Model Size: 424.88 MB\n",
            "Distlbert Model Size: 262.64 MB\n"
          ]
        }
      ],
      "source": [
        "size_bert = get_model_size(BERT_MODEL_NAME)\n",
        "size_dstlbert = get_model_size(DSTLBERT_MODEL_NAME)\n",
        "\n",
        "print(f\"Bert Model Size: {size_bert:.2f} MB\")\n",
        "print(f\"Distlbert Model Size: {size_dstlbert:.2f} MB\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
